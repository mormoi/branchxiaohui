- hosts: test_fz
  remote_user: root
  vars:
  - remote_dir: /root/
  - local_dir: /root/fangzhou
  - conf_dir: /root/fangzhou/conf
  - pack_dir: /root/fangzhou/packet
  tasks:
  - name: create user
    user: name={{ item.name }} state=present system={{ item.system }}
    with_items:
      - { name: hdfs, system: no }
# 这三个包在自带的镜像内可以找到
  - name: install dependence packet
    yum: name={{ item.name }} state={{ item.state }}
    with_items:
      - { name: libselinux-python, state: latest}
      - { name: libselinux, state: latest}
      - { name: libselinux-utils, state: latest}
  - name: modify core arguments
    lineinfile: dest=/etc/sysctl.conf line="{{ item }}"
    with_items:
      - "vm.swappiness = 0"
      - "net.ipv6.conf.all.disable_ipv6 = 1"
      - "net.ipv4.tcp_timestamps = 1"
      - "net.ipv4.tcp_tw_recycle = 1"
    notify:
      - reload sysctl.conf
  - name: copy /root/fangzhou/conf/ipv6off.conf to remote
    copy: src={{ item.src }} dest={{ item.dest }} owner=root group=root mode='0644'
    with_items:
      - { src: '{{ conf_dir }}/ipv6off.conf', dest: '/etc/modprobe.d/' }
      - { src: '{{ conf_dir }}/limits.conf', dest: '/etc/security/' }
      - { src: '{{ conf_dir }}/90-nproc.conf', dest: '/etc/security/limits.d/' }
      - { src: '{{ conf_dir}}/hosts', dest: '/etc/' }
      - { src: '{{ conf_dir }}/profile/hadoop.sh', dest: '/etc/profile.d/' }
      - { src: '{{ pack_dir }}/lzo-2.04-1.el5.rf.x86_64.rpm', dest: '/root/' }
      - { src: '{{ pack_dir }}/lzo-devel-2.04-1.el5.rf.x86_64.rpm', dest: '/root/' }
      - { src: '{{ pack_dir }}/lzop-1.03-2.el5.x86_64.rpm', dest: '/root/' }
    tags: conf1
  - name: get hostname
    shell: grep '{{ ansible_default_ipv4.address }}' /etc/hosts | awk "{print \$2}"
    register: hname
  - name: modify hostname
    hostname: name="{{ hname.stdout }}"
  - name: modify mount argument
    lineinfile: dest=/etc/fstab regexp="{{ item.regexp }}" line="{{ item.line }}" backrefs=yes
    with_items:
      - { regexp: "/dev/sda3 /data1 ext4 defaults 0 0", line: '/dev/sda3 /data1   ext4  defaults,noatime 0 0'}
      - { regexp: "/dev/sdb1 /data2 ext4 defaults 0 0", line: '/dev/sdb1 /data2   ext4  defaults,noatime 0 0'}
      - { regexp: "/dev/sdc1 /data3 ext4 defaults 0 0", line: '/dev/sdc1 /data3   ext4  defaults,noatime 0 0'}
      - { regexp: "/dev/sdd1 /data4 ext4 defaults 0 0", line: '/dev/sdd1 /data4   ext4  defaults,noatime 0 0'}
  - name: install jdk,hadoop,hbase
    unarchive: src={{ item.src }} dest={{ item.dest }} owner={{ item.owner }} group={{ item.group }} creates={{ item.creates }}
    with_items:
      - {src: '{{ pack_dir }}/jdk1.7.0_67.tar.gz', dest: '/usr/local/', owner: root, group: root, creates: '/usr/local/jdk1.7.0_67'}
      - {src: '{{ pack_dir }}/hadoop-2.5.1.tar.gz', dest: '/usr/local/', owner: hdfs, group: hdfs, creates: '/usr/local/hadoop-2.5.1'}
      - {src: '{{ pack_dir }}/hbase-1.1.2.tar.gz', dest: '/usr/local/', owner: hdfs, group: hdfs, creates: '/usr/local/hbase-1.1.2'}
  - name: create hadoop data,log, dir,install supervisord
    file: path={{ item.path }} owner={{ item.owner }} group={{ item.group }} mode={{ item.mode }} state={{ item.state }}
    with_items:
      - {path: '/data1/hadoop/journal', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data2/hadoop/journal', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data3/hadoop/journal', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/hadoop/journal', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/dfs/name', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data2/hadoop/dfs/name', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data3/hadoop/dfs/name', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/hadoop/dfs/name', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/dfs/data', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data2/hadoop/dfs/data', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data3/hadoop/dfs/data', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/hadoop/dfs/data', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/zookeeper/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data2/hadoop/zookeeper/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data3/hadoop/zookeeper/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/hadoop/zookeeper/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/hbase/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data2/hadoop/hbase/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data3/hadoop/hbase/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/hadoop/hbase/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/log/yarn', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/log/hadoop', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/pid/yarn', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/pid/hadoop', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/metrics', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/gclog', owner: hdfs, group: hdfs, mode: '0777', state: directory}
      - {path: '/data1/hadoop/dfs/data', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/local', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/log/yarn', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data1/hadoop/socket/', owner: hdfs, group: hdfs, mode: '0755', state: directory}
      - {path: '/data4/tmp', owner: root, group: root, mode: '0777', state: directory}
  - name: copy hadoop, hbase conf file
    copy: src={{ item.src }} dest={{ item.dest }} owner={{ item.owner }} group={{ item.group }} mode={{ item.mode }}
    tags: copy_conf
    with_items:
      - { src: "{{ conf_dir }}/hadoop/core-site.xml", dest: '/usr/local/hadoop-2.5.1/etc/hadoop/', owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hadoop/hdfs-site.xml", dest: '/usr/local/hadoop-2.5.1/etc/hadoop/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hadoop/mapred-site.xml", dest: '/usr/local/hadoop-2.5.1/etc/hadoop/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hadoop/yarn-site.xml", dest: '/usr/local/hadoop-2.5.1/etc/hadoop/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hadoop/slaves", dest: '/usr/local/hadoop-2.5.1/etc/hadoop/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hbase/backup-masters", dest: '/usr/local/hbase-1.1.2/conf/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hbase/hbase-site.xml", dest: '/usr/local/hbase-1.1.2/conf/',owner: hdfs, group: hdfs, mode: '0644'}
      - { src: "{{ conf_dir }}/hbase/regionservers", dest: '/usr/local/hbase-1.1.2/conf/',owner: hdfs, group: hdfs, mode: '0644'}
    
  - name: stop iptables
    service: name={{ item.name }} state={{ item.state }} enabled={{ item.enabled }}
    with_items:
      - { name: iptables, state: stopped, enabled: no}
  - name: install lzo packet
    yum: name={{ item.name }} state={{ item.state }}
    with_items:
      - { name: /root/lzo-2.04-1.el5.rf.x86_64.rpm, state: present }
      - { name: /root/lzo-devel-2.04-1.el5.rf.x86_64.rpm, state: present }
      - { name: /root/lzop-1.03-2.el5.x86_64.rpm, state: present }

  handlers:
  - name: reload sysctl.conf
    shell: sysctl -p
    ignore_errors: True
  
